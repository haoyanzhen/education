{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习简介\n",
    "\n",
    "Date: 2025-01-23\n",
    "\n",
    "## 理论简介\n",
    "\n",
    "机器学习（Machine Learning，简称 ML）是人工智能（AI）的一个子领域，其核心是开发能够从经验中学习并改进的系统，而不需要明确编写程序来完成每一项任务。与传统编程不同，机器学习模型通过识别数据中的模式来进行预测、决策或采取行动。\n",
    "\n",
    "以下是机器学习的基础概念和原理：\n",
    "\n",
    "---\n",
    "\n",
    "### 核心概念\n",
    "\n",
    "1. **数据驱动学习：**  \n",
    "   机器学习模型依赖数据来学习model（模型）和relationship（映射关系）。因此机器学习模型极度依赖数据的质量和数量\n",
    "\n",
    "2. **特征：**  \n",
    "   即数据中可测量的属性或特性，用于训练模型。清洗数据并选择合适的特征（特征工程）是构建高效模型的关键。\n",
    "\n",
    "3. **模型：**  \n",
    "   模型是一个数学或计算结构，用于根据输入数据进行预测或决策。\n",
    "\n",
    "4. **训练和测试：**  \n",
    "   - **训练（Training）：** 指通过将数据输入模型，让其学习数据中的模式。  \n",
    "   - **测试（Testing）：** 使用未见过的数据评估模型的性能。\n",
    "\n",
    "5. **监督学习、无监督学习和强化学习：**  \n",
    "   - **监督学习（Supervised Learning）：** 从有标签的数据中学习（例如，根据历史数据预测房价）。  \n",
    "   - **无监督学习（Unsupervised Learning）：** 在无标签的数据中寻找模式（例如，聚类相似客户）。  \n",
    "   - **强化学习（Reinforcement Learning）：** 通过试错的方式增强学习（例如，下棋）。\n",
    "\n",
    "6. **过拟合和欠拟合：**  \n",
    "   - **过拟合（Overfitting）：** 模型学习了训练数据中的噪声，导致对新数据的泛化能力较差。  \n",
    "   - **欠拟合（Underfitting）：** 模型未能充分学习数据中的模式，导致训练集和测试集表现都较差。\n",
    "\n",
    "7. **评估指标：**  \n",
    "   使用准确率、精确率、召回率、F1分数、均方误差（MSE）等指标评估模型性能。\n",
    "\n",
    "---\n",
    "\n",
    "### 基本原理\n",
    "\n",
    "1. **从数据中学习：**  \n",
    "   - 机器学习算法通过训练数据学习一个函数 \\( f(x) \\)，该函数将输入 \\( x \\) 映射到输出 \\( y \\)。\n",
    "\n",
    "2. **优化：**  \n",
    "   - 算法通过优化目标函数（例如，最小化误差或最大化准确率）来提升模型性能。\n",
    "\n",
    "3. **泛化：**  \n",
    "   - 模型的目标是不仅在训练数据上表现良好，还能在未见数据（测试集或真实世界数据）上表现出色。泛化能力通常与模型的鲁棒性和训练数据与真实数据的差异有关。\n",
    "\n",
    "4. **迭代与反馈：**  \n",
    "   - 机器学习是一个迭代过程，模型通过训练、评估和优化不断改进。\n",
    "\n",
    "5. **偏差-方差权衡（Bias-Variance Tradeoff）：**  \n",
    "   - 在偏差（模型假设过于简单导致的误差）和方差（模型对训练数据敏感导致的误差）之间找到平衡，是构建鲁棒模型的关键。\n",
    "\n",
    "6. **概率与统计基础：**  \n",
    "   - 机器学习依赖概率和统计来量化不确定性、衡量性能，并在不确定情况下做出决策。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM(Support Vector Machine)\n",
    "\n",
    "支持向量机（Support Vector Machine, SVM）是一种经典的机器学习算法，常用于分类和回归问题。SVM的核心思想是通过找到一个超平面，将数据分为不同的类别，同时尽可能地最大化分类边界的间隔。对于非线性可分数据，SVM通过核函数将数据映射到高维空间，使得在高维空间中实现线性可分。\n",
    "\n",
    "---\n",
    "\n",
    "### SVM的基本特点\n",
    "\n",
    "1. **适用于分类问题，即0维或1维问题：**\n",
    "   其输出通常适用于结果是0/1的0维问题，或结果是0/1/2/3...的离散型1维问题\n",
    "\n",
    "2. **适用于线性和非线性数据：**  \n",
    "   使用核函数（如线性核、高斯核、多项式核）处理非线性问题。\n",
    "   \n",
    "3. **对小样本和高维数据表现良好：**  \n",
    "   SVM尤其适合特征数多、样本量小的场景。\n",
    "\n",
    "4. **支持多类分类：**  \n",
    "   通过“1对1”或“1对多”策略扩展为多分类任务。\n",
    "\n",
    "---\n",
    "\n",
    "### SVM的Python实现\n",
    "\n",
    "SVM在Python中可以通过**scikit-learn**库实现。以下是一个简单的分类示例：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 加载示例数据集（如鸢尾花数据集）\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  # 特征\n",
    "y = iris.target  # 标签\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 创建支持向量机模型\n",
    "svm_model = SVC(kernel='rbf', C=1, gamma='scale')  # 使用RBF核\n",
    "svm_model.fit(X_train, y_train)  # 训练模型\n",
    "\n",
    "# 模型预测与评估\n",
    "y_pred = svm_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"模型准确率: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN（Artificial Neural Network）\n",
    "\n",
    "人工神经网络是一种受生物神经系统启发的计算模型，旨在模拟人类大脑的学习和决策过程。ANN通过多个简单的处理单元（即神经元）和它们之间的连接（权重）来处理复杂的非线性问题，广泛应用于分类、回归、图像识别、自然语言处理等领域。\n",
    "\n",
    "---\n",
    "\n",
    "### ANN的基本概念\n",
    "\n",
    "1. **神经元（Neuron）：**  \n",
    "   ANN的基本构成单元。每个神经元接收多个输入信号，并通过加权求和和激活函数处理后输出结果。\n",
    "\n",
    "2. **层（Layer）：**  \n",
    "   - **输入层（Input Layer）：** 接收原始数据输入。  \n",
    "   - **隐藏层（Hidden Layer）：** 位于输入层和输出层之间，负责提取数据的特征和模式。  \n",
    "   - **输出层（Output Layer）：** 生成最终预测结果。\n",
    "\n",
    "3. **权重（Weight）：**  \n",
    "   每个连接都有一个权重，用于表示输入信号的重要性。权重是模型通过学习优化的关键参数。\n",
    "\n",
    "4. **偏置（Bias）：**  \n",
    "   为每个神经元添加的常数项，用于调整激活函数的输出。\n",
    "\n",
    "5. **激活函数（Activation Function）：**  \n",
    "   非线性函数，用于引入复杂的非线性关系。常见的激活函数包括：\n",
    "   - ReLU（Rectified Linear Unit）\n",
    "   - Sigmoid\n",
    "   - Tanh\n",
    "\n",
    "6. **损失函数（Loss Function）：**  \n",
    "   衡量模型预测值与真实值之间的差距，指导模型优化。常见损失函数有均方误差（MSE）、交叉熵等。\n",
    "\n",
    "7. **优化器（Optimizer）：**  \n",
    "   用于更新模型参数（权重和偏置），如随机梯度下降（SGD）和Adam。\n",
    "\n",
    "---\n",
    "\n",
    "### **ANN的基本原理**\n",
    "\n",
    "1. **前向传播（Forward Propagation）：**  \n",
    "   数据从输入层开始，经过隐藏层逐步计算到输出层，每一层的输出成为下一层的输入。\n",
    "\n",
    "2. **损失计算：**  \n",
    "   通过损失函数计算模型预测结果与真实值之间的误差。\n",
    "\n",
    "3. **反向传播（Back Propagation）：**  \n",
    "   根据误差，通过链式法则计算每个权重对误差的贡献，并反向更新权重。\n",
    "\n",
    "4. **迭代优化：**  \n",
    "   通过多轮前向传播和反向传播，不断调整权重和偏置，使模型预测结果更加准确。\n",
    "\n",
    "5. **泛化能力：**  \n",
    "   模型的目标是对训练数据学习，同时在测试数据（新数据）上表现良好。\n",
    "\n",
    "---\n",
    "\n",
    "### **ANN的特点**\n",
    "\n",
    "1. **非线性建模能力：**  \n",
    "   通过激活函数和多层结构，ANN可以处理复杂的非线性问题。\n",
    "\n",
    "2. **自适应性：**  \n",
    "   通过学习调整权重和偏置，ANN能够适应不同类型的数据和任务。\n",
    "\n",
    "3. **鲁棒性：**  \n",
    "   ANN对噪声数据有一定的容忍能力，尤其是在大数据场景下表现优异。\n",
    "\n",
    "4. **可扩展性：**  \n",
    "   通过增加隐藏层和神经元数量，可以提升模型的表达能力（但需要注意避免过拟合）。\n",
    "\n",
    "---\n",
    "\n",
    "### **ANN在Python中的应用**\n",
    "\n",
    "在Python中，可以使用**TensorFlow**或**PyTorch**等深度学习框架构建ANN模型。以下是一个使用TensorFlow实现简单分类的示例：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 创建示例数据集\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 构建ANN模型\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),  # 隐藏层1\n",
    "    Dense(16, activation='relu'),  # 隐藏层2\n",
    "    Dense(1, activation='sigmoid')  # 输出层\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# 评估模型\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"模型准确率: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
